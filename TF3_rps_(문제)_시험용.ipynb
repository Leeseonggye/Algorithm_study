{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF3-rps (문제)의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leeseonggye/Algorithm_study/blob/main/TF3_rps_(%EB%AC%B8%EC%A0%9C)_%EC%8B%9C%ED%97%98%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg-hP0itZxmX"
      },
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer Vision with CNNs\n",
        "#\n",
        "# For this task you will build a classifier for Rock-Paper-Scissors \n",
        "# based on the rps dataset.\n",
        "#\n",
        "# IMPORTANT: Your final layer should be as shown, do not change the\n",
        "# provided code, or the tests may fail\n",
        "#\n",
        "# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "# So ensure that your input layer is designed accordingly, or the tests\n",
        "# may fail. \n",
        "#\n",
        "# NOTE THAT THIS IS UNLABELLED DATA. \n",
        "# You can use the ImageDataGenerator to automatically label it\n",
        "# and we have provided some starter code.\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 3 - rps\n",
        "# val_loss: 0.0871\n",
        "# val_acc: 0.97\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "    urllib.request.urlretrieve(url, 'rps.zip')\n",
        "    local_zip = 'rps.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "    zip_ref.extractall('tmp/')\n",
        "    zip_ref.close()\n",
        "\n",
        "\n",
        "    TRAINING_DIR = \"tmp/rps/\"\n",
        "    training_datagen = ImageDataGenerator(\n",
        "    # YOUR CODE HERE)\n",
        "\n",
        "\n",
        "\n",
        "    train_generator = # YOUR CODE HERE\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "                                        \n",
        "\n",
        "\n",
        "    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-rps.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ksWsc_tD4L"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeQplqrYtD6-"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "urllib.request.urlretrieve(url, 'rps.zip')\n",
        "local_zip = 'rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()\n",
        "TRAINING_DIR = \"tmp/rps/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v7uA_nWtD9m"
      },
      "source": [
        "training_datagen = ImageDataGenerator(\n",
        "    rotation_range = 0.2,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    rescale = 1/255,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.2\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JzFHMS7tEAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d75c000-f833-4efa-94f4-48dee66c2ab4"
      },
      "source": [
        "train_generator = training_datagen.flow_from_directory(directory= TRAINING_DIR,\n",
        "                                                       target_size = (150,150),\n",
        "                                                       subset = 'training')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2016 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq2lIj0Xuwws",
        "outputId": "6d652dd1-54f1-4a54-b6fa-82eedc267e8b"
      },
      "source": [
        "valid_generator = training_datagen.flow_from_directory(directory= TRAINING_DIR,\n",
        "                                                       target_size = (150,150),\n",
        "                                                       subset = 'validation')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 504 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nu_MdwzvAf9"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    Conv2D(64,(3,3),activation= 'relu', input_shape = (150,150,3)),\n",
        "                                    MaxPooling2D((2,2),),\n",
        "                                    Conv2D(32,(3,3),activation= 'relu'),\n",
        "                                    MaxPooling2D((2,2),),\n",
        "                                    Conv2D(16,(3,3),activation= 'relu'),\n",
        "                                    MaxPooling2D((2,2),),\n",
        "                                    Flatten(),\n",
        "                                    Dropout(0.5),\n",
        "                                    Dense(512, activation='relu'),\n",
        "                                    Dense(3, activation= 'softmax')\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcp1wHu0wMLO",
        "outputId": "f2359d7a-4227-4050-b704-09135ff0b485"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 72, 72, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 34, 34, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4624)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4624)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               2368000   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 2,394,419\n",
            "Trainable params: 2,394,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "359qFVvYwTiR"
      },
      "source": [
        "checkpoint_path = 'tmp_mycheckpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(filepath = checkpoint_path, monitor = 'val_loss',\n",
        "                             save_best_only = True, save_weights_only = True,\n",
        "                             verbose = 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkm6QAEWw0mi"
      },
      "source": [
        "model.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiB-d3gdw9ll",
        "outputId": "b63ea9fb-7b52-4459-ad4b-d6c780d68642"
      },
      "source": [
        "model.fit(train_generator, validation_data= (valid_generator),\n",
        "          epochs = 25, verbose = 1,\n",
        "          callbacks = [checkpoint],\n",
        "          steps_per_epoch = len(train_generator),\n",
        "          validation_steps = len(valid_generator),\n",
        "          )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "63/63 [==============================] - 22s 346ms/step - loss: 0.9834 - acc: 0.5060 - val_loss: 0.9390 - val_acc: 0.4643\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.93900, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 2/25\n",
            "63/63 [==============================] - 21s 338ms/step - loss: 0.4961 - acc: 0.8090 - val_loss: 0.6072 - val_acc: 0.6528\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.93900 to 0.60723, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 3/25\n",
            "63/63 [==============================] - 22s 342ms/step - loss: 0.2679 - acc: 0.8998 - val_loss: 0.7353 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.60723\n",
            "Epoch 4/25\n",
            "63/63 [==============================] - 22s 343ms/step - loss: 0.2154 - acc: 0.9206 - val_loss: 0.4471 - val_acc: 0.7321\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.60723 to 0.44707, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 5/25\n",
            "63/63 [==============================] - 22s 343ms/step - loss: 0.1607 - acc: 0.9449 - val_loss: 0.6251 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.44707\n",
            "Epoch 6/25\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.1244 - acc: 0.9638 - val_loss: 0.6201 - val_acc: 0.7103\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.44707\n",
            "Epoch 7/25\n",
            "63/63 [==============================] - 22s 355ms/step - loss: 0.0773 - acc: 0.9767 - val_loss: 0.2516 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.44707 to 0.25162, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 8/25\n",
            "63/63 [==============================] - 22s 349ms/step - loss: 0.0751 - acc: 0.9757 - val_loss: 0.2268 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.25162 to 0.22681, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 9/25\n",
            "63/63 [==============================] - 22s 343ms/step - loss: 0.0526 - acc: 0.9841 - val_loss: 0.2362 - val_acc: 0.9127\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.22681\n",
            "Epoch 10/25\n",
            "63/63 [==============================] - 22s 344ms/step - loss: 0.0531 - acc: 0.9831 - val_loss: 0.8476 - val_acc: 0.6885\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.22681\n",
            "Epoch 11/25\n",
            "63/63 [==============================] - 22s 342ms/step - loss: 0.0512 - acc: 0.9836 - val_loss: 0.3672 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.22681\n",
            "Epoch 12/25\n",
            "63/63 [==============================] - 22s 343ms/step - loss: 0.0627 - acc: 0.9807 - val_loss: 0.3601 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.22681\n",
            "Epoch 13/25\n",
            "63/63 [==============================] - 21s 340ms/step - loss: 0.0502 - acc: 0.9846 - val_loss: 0.2597 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.22681\n",
            "Epoch 14/25\n",
            "63/63 [==============================] - 22s 342ms/step - loss: 0.0423 - acc: 0.9846 - val_loss: 0.2323 - val_acc: 0.9226\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.22681\n",
            "Epoch 15/25\n",
            "63/63 [==============================] - 21s 340ms/step - loss: 0.0381 - acc: 0.9866 - val_loss: 0.4630 - val_acc: 0.7956\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.22681\n",
            "Epoch 16/25\n",
            "63/63 [==============================] - 22s 342ms/step - loss: 0.0696 - acc: 0.9772 - val_loss: 0.2514 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.22681\n",
            "Epoch 17/25\n",
            "63/63 [==============================] - 22s 342ms/step - loss: 0.0219 - acc: 0.9940 - val_loss: 0.1531 - val_acc: 0.9464\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.22681 to 0.15312, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 18/25\n",
            "63/63 [==============================] - 22s 345ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.1572 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.15312\n",
            "Epoch 19/25\n",
            "63/63 [==============================] - 21s 341ms/step - loss: 0.0205 - acc: 0.9940 - val_loss: 0.0711 - val_acc: 0.9821\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.15312 to 0.07107, saving model to tmp_mycheckpoint.ckpt\n",
            "Epoch 20/25\n",
            "63/63 [==============================] - 21s 338ms/step - loss: 0.0214 - acc: 0.9916 - val_loss: 0.3926 - val_acc: 0.8155\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.07107\n",
            "Epoch 21/25\n",
            "63/63 [==============================] - 21s 339ms/step - loss: 0.0279 - acc: 0.9916 - val_loss: 0.4670 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.07107\n",
            "Epoch 22/25\n",
            "63/63 [==============================] - 22s 343ms/step - loss: 0.0215 - acc: 0.9931 - val_loss: 0.2961 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.07107\n",
            "Epoch 23/25\n",
            "63/63 [==============================] - 21s 341ms/step - loss: 0.0245 - acc: 0.9921 - val_loss: 0.1953 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.07107\n",
            "Epoch 24/25\n",
            "63/63 [==============================] - 21s 340ms/step - loss: 0.0142 - acc: 0.9950 - val_loss: 0.6487 - val_acc: 0.7639\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.07107\n",
            "Epoch 25/25\n",
            "63/63 [==============================] - 22s 343ms/step - loss: 0.0111 - acc: 0.9955 - val_loss: 0.1102 - val_acc: 0.9524\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.07107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd9500e4e90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhTZ6KG_xOOg",
        "outputId": "248c0281-afe9-4eb6-cbff-3040048d10a7"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd8b3438b90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-nU2EcI3aFN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}